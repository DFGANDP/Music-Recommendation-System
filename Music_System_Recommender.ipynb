{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXGcz69mT30g"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification\n",
        "!unzip /content/gtzan-dataset-music-genre-classification.zip # gtzan rozpakuj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rY7KIBEzd63u"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/Music_Dataset/dataset.zip . \n",
        "!cp /content/drive/MyDrive/Music_Dataset/CNN_CLASIFIER_annotations_withgtzan_v2.csv .\n",
        "!unzip dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVp6D-h6d8mE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# USUN DISCO I COUNTRY PRZERZUC DO FOLDERU\n",
        "for dir in os.listdir(\"/content/Data/genres_original\"):\n",
        "  for file in os.listdir(\"/content/Data/genres_original/\"+dir):\n",
        "    if \"disco\" in file:\n",
        "      os.remove(\"/content/Data/genres_original/\"+dir+\"/\"+file)\n",
        "    elif \"country\" in file:\n",
        "      os.remove(\"/content/Data/genres_original/\"+dir+\"/\"+file)\n",
        "    else:\n",
        "      if file.endswith(\".wav\"):\n",
        "        os.rename(\"/content/Data/genres_original/\"+dir+\"/\"+file, \"/content/dataset/\"+file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QAPdK9ud-cb"
      },
      "outputs": [],
      "source": [
        "import math, random\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "from IPython.display import Audio\n",
        "\n",
        "class AudioUtil():\n",
        "  # ----------------------------\n",
        "  # Load an audio file. Return the signal as a tensor and the sample rate\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def open(audio_file):\n",
        "    sig, sr = torchaudio.load(audio_file)\n",
        "    return (sig, sr)\n",
        "\n",
        "  # ----------------------------\n",
        "  # Convert the given audio to the desired number of channels\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def rechannel(aud, new_channel):\n",
        "    sig, sr = aud\n",
        "\n",
        "    if (sig.shape[0] == new_channel):\n",
        "      # Nothing to do\n",
        "      return aud\n",
        "\n",
        "    if (new_channel == 1):\n",
        "      # Convert from stereo to mono by selecting only the first channel\n",
        "      resig = sig[:1, :]\n",
        "    elif (new_channel == 3):\n",
        "      resig = sig[:1, :]\n",
        "      resig = torch.cat(3*[resig])\n",
        "      '''\n",
        "      print(sig.shape)\n",
        "      print(sig.size())\n",
        "      channel = sig[0,:]\n",
        "      \n",
        "      resig = sig.expand(3, -1)\n",
        "\n",
        "      x[0,:] = channel\n",
        "      x[1,:] = channel\n",
        "      x[2,:] = channel\n",
        "      '''\n",
        "    else:\n",
        "      # Convert from mono to stereo by duplicating the first channel\n",
        "      resig = torch.cat([sig, sig])\n",
        "\n",
        "    return ((resig, sr))\n",
        "\n",
        "  # ----------------------------\n",
        "  # Since Resample applies to a single channel, we resample one channel at a time\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def resample(aud, newsr):\n",
        "    sig, sr = aud\n",
        "\n",
        "    if (sr == newsr):\n",
        "      # Nothing to do\n",
        "      return aud\n",
        "\n",
        "    num_channels = sig.shape[0]\n",
        "    # Resample first channel\n",
        "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
        "    if (num_channels > 1):\n",
        "      # Resample the second channel and merge both channels\n",
        "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
        "      resig = torch.cat([resig, retwo])\n",
        "\n",
        "    return ((resig, newsr))\n",
        "\n",
        "  # ----------------------------\n",
        "  # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def pad_trunc(aud, max_ms): # TU WCHODZI ILE MA TRWAC\n",
        "    sig, sr = aud\n",
        "    num_rows, sig_len = sig.shape\n",
        "    max_len = sr//1000 * max_ms \n",
        "\n",
        "    if (sig_len > max_len):\n",
        "      # Truncate the signal to the given length\n",
        "      sig = sig[:,:max_len]\n",
        "\n",
        "    elif (sig_len < max_len):\n",
        "      # Length of padding to add at the beginning and end of the signal\n",
        "      pad_begin_len = random.randint(0, max_len - sig_len)\n",
        "      pad_end_len = max_len - sig_len - pad_begin_len\n",
        "\n",
        "      # Pad with 0s\n",
        "      pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
        "      pad_end = torch.zeros((num_rows, pad_end_len))\n",
        "\n",
        "      sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
        "      \n",
        "    return (sig, sr)\n",
        "\n",
        "  # ---------------------------- DATA AUGUMENTATION\n",
        "  # Shifts the signal to the left or right by some percent. Values at the end\n",
        "  # are 'wrapped around' to the start of the transformed signal.\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def time_shift(aud, shift_limit):\n",
        "    sig,sr = aud\n",
        "    _, sig_len = sig.shape\n",
        "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
        "    return (sig.roll(shift_amt), sr)\n",
        "  \n",
        "  # ----------------------------\n",
        "  # Generate a Spectrogram\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
        "    sig,sr = aud\n",
        "    top_db = 80\n",
        "\n",
        "    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
        "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
        "\n",
        "    # Convert to decibels\n",
        "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
        "    return (spec)\n",
        "  \n",
        "\n",
        "  # ---------------------------- MEL AUGUMENTATION\n",
        "  # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
        "  # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
        "  # overfitting and to help the model generalise better. The masked sections are\n",
        "  # replaced with the mean value.\n",
        "  # ----------------------------\n",
        "  @staticmethod\n",
        "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
        "    _, n_mels, n_steps = spec.shape\n",
        "    mask_value = spec.mean()\n",
        "    aug_spec = spec\n",
        "\n",
        "    freq_mask_param = max_mask_pct * n_mels\n",
        "    for _ in range(n_freq_masks):\n",
        "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "    time_mask_param = max_mask_pct * n_steps\n",
        "    for _ in range(n_time_masks):\n",
        "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
        "\n",
        "    return aug_spec\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchaudio\n",
        "\n",
        "# ----------------------------\n",
        "# Sound Dataset\n",
        "# ----------------------------\n",
        "class SoundDS(Dataset):\n",
        "  def __init__(self, df, data_path, duration=30000, shift_pct=0.4):\n",
        "    self.df = df #\n",
        "    self.data_path = str(data_path) # /content/dataset/\n",
        "    self.duration = duration # tu bylo 4000 ms czyli 4s\n",
        "    self.sr = 44100\n",
        "    self.channel = 3 # ZMIANA NA 3 kanaly zeby sie zgadzalo\n",
        "    self.shift_pct = shift_pct\n",
        "            \n",
        "  # ----------------------------\n",
        "  # Number of items in dataset\n",
        "  # ----------------------------\n",
        "  def __len__(self):\n",
        "    return len(self.df)    \n",
        "    \n",
        "  # ----------------------------\n",
        "  # Get i'th item in dataset\n",
        "  # ----------------------------\n",
        "  def __getitem__(self, idx):\n",
        "    # Absolute file path of the audio file - concatenate the audio directory with\n",
        "    # the relative path\n",
        "    audio_file = self.data_path + self.df.loc[idx, 'filename'] # tu bylo relative_path zamiast filename\n",
        "    # Get the Class ID\n",
        "    class_id = self.df.loc[idx, 'label'] # tu bylo classID zamiast label\n",
        "    class_id = int(class_id)\n",
        "    aud = AudioUtil.open(audio_file) # jakby dodac to.device!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    # Some sounds have a higher sample rate, or fewer channels compared to the\n",
        "    # majority. So make all sounds have the same number of channels and same \n",
        "    # sample rate. Unless the sample rate is the same, the pad_trunc will still\n",
        "    # result in arrays of different lengths, even though the sound duration is\n",
        "    # the same.\n",
        "    reaud = AudioUtil.resample(aud, self.sr)\n",
        "    rechan = AudioUtil.rechannel(reaud, self.channel)\n",
        "\n",
        "    dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
        "    shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
        "    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None) # tu mozna sie pobawic parametrami\n",
        "    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
        "\n",
        "    return aug_sgram, class_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwpiOZbLweIS"
      },
      "source": [
        "# save tensor to png\n",
        "nie dziala\n",
        "**Save spectrograms to png for faster training**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "DATASET ZWRACA \n",
        "\n",
        "return aug_sgram, class_id, self.df.loc[idx, 'filename']\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKrqoobxwZ_y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "df = pd.read_csv(\"/content/CNN_CLASIFIER_annotations_withgtzan_v2.csv\")\n",
        "data_path = \"/content/dataset/\"\n",
        "\n",
        "myds = SoundDS(df, data_path)\n",
        "mel_png = torch.utils.data.DataLoader(myds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(myds.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zlvAZyYwdks",
        "outputId": "3aea415b-4980-4585-e9b8-986d046ed6d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(-35.1965)\n",
            "tensor(0, dtype=torch.uint8)\n"
          ]
        }
      ],
      "source": [
        "from torchvision.utils import save_image\n",
        "import cv2 as cv\n",
        "\n",
        "def mels_to_png(mel_png):\n",
        "    for image, label, audio_filename in mel_png:\n",
        "        # dostaje 1 zjdecie i 1 label sprawdzic shape\n",
        "        image = torch.squeeze(image)\n",
        "        #print(image.shape)\n",
        "        #print(torch.min(image))\n",
        "        #print(label.shape)\n",
        "        #print(label)\n",
        "        #print(audio_filename) # nazwa pliku\n",
        "        save_image(image, 'image.png')\n",
        "        break\n",
        "    return image\n",
        "original_tensor = mels_to_png(mel_png)\n",
        "print(torch.min(original_tensor))\n",
        "\n",
        "def read_pnt_to_mel(png_path):\n",
        "    image = cv.imread(png_path)\n",
        "    image = torch.from_numpy(image)\n",
        "    return image\n",
        "\n",
        "loaded_tensor = read_pnt_to_mel(\"/content/image.png\")\n",
        "\n",
        "loaded_tensor = loaded_tensor.permute(2, 0, 1)\n",
        "print(torch.min(loaded_tensor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yM5ktUW5h1W"
      },
      "source": [
        "# inaa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oX3z4YmakUj"
      },
      "outputs": [],
      "source": [
        "audio_classes = ['blues', 'classical', 'electronic', 'electronic(vibe)', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728',\n",
        "              '#9467bd', '#8c564b', '#e377c2', '#7f7f7f',\n",
        "              '#bcbd22', '#17becf']\n",
        "label_dict = {\n",
        "    \"blues\" : 0,\n",
        "    \"classical\" : 1,\n",
        "    \"electronic\" : 2,\n",
        "    \"electronic(vibe)\" : 3,\n",
        "    \"hiphop\" : 4,\n",
        "    \"jazz\" : 5,\n",
        "    \"metal\" : 6,\n",
        "    \"pop\" : 7,\n",
        "    \"reggae\" : 8,\n",
        "    \"rock\" : 9\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUh1zZPOeA68",
        "outputId": "fe3493d7-a5ce-452e-ec1f-e1e7ced57d40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 344])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import random_split\n",
        "import numpy as np\n",
        "\n",
        "############## POEKSPERYMENTOWAC Z BATCH_SIZE\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "df = pd.read_csv(\"/content/CNN_CLASIFIER_annotations_withgtzan_v2.csv\")\n",
        "data_path = \"/content/dataset/\"\n",
        "\n",
        "myds = SoundDS(df, data_path, duration=4000, shift_pct=0.4)\n",
        "\n",
        "# Random split of 80:20 between training and validation\n",
        "num_items = len(myds)\n",
        "num_train = round(num_items * 0.8)\n",
        "num_val = num_items - num_train\n",
        "train_ds, test_ds = random_split(myds, [num_train, num_val])\n",
        "\n",
        "# Create training and validation data loaders\n",
        "# batch_size jak dobierac spradzic\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "myds[0][0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZBwJkj_bm23"
      },
      "source": [
        "# Baseline: Classification with softmax\n",
        "\n",
        "1. RESNETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "cb1bd6b776034bf0a3ed8f7360e1f786",
            "810190a8d2ab4191a09425043dcfa6ec",
            "d5d13f06c0224691a814d3ed5c43a49d",
            "69a73f4d56314142966c45bb276610e9",
            "9fd16236b9bb4aa4bb5c9ba253ba36da",
            "c0b60449d2bd4a40b66865b1fbae09fb",
            "427bd2d58ae045a78cad739d61ec5cec",
            "56e2c1e656d444bca67da2dfb057a3b1",
            "0d37f049421647aabe68780c4ba21baf",
            "223f473b59b0449a90e012bec28f56d4",
            "cc14244e8b4e4196ae07684d59f97771"
          ]
        },
        "id": "pV9BLns2g5gC",
        "outputId": "d2299064-8426-49c5-8cfb-d382c5fdb1df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb1bd6b776034bf0a3ed8f7360e1f786",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/230M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512])\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Feature Extractor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "class EmbeddingNet(nn.Module):\n",
        "    def __init__(self, latent_dim=128, architecture=18):\n",
        "        super(EmbeddingNet, self).__init__()\n",
        "        self.architecture = architecture\n",
        "        self.feature_extractor = self._getResnet(latent_dim=latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "    def _getResnet(self,latent_dim):\n",
        "        '''\n",
        "        Sprawdzic czy daje tez FC\n",
        "        '''\n",
        "        if self.architecture == 18:\n",
        "            model = models.resnet18(pretrained=True)\n",
        "        elif self.architecture == 34:\n",
        "            model = models.resnet34(pretrained=True)\n",
        "        elif self.architecture == 50:\n",
        "            model = models.resnet50(pretrained=True)\n",
        "        elif self.architecture == 101:\n",
        "            model = models.resnet101(pretrained=True)\n",
        "        elif self.architecture == 152:\n",
        "            model = models.resnet152(pretrained=True)\n",
        "        else: print(\"MODEL NOT LOADED\")\n",
        "        \n",
        "        for param in model.parameters():\n",
        "            param.requires_grad= False # freeze beggining layer\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_features, latent_dim)\n",
        "    \n",
        "\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "class ClassificationNet(nn.Module):\n",
        "    def __init__(self, embedding_net, n_classes, latent_dim):\n",
        "        super(ClassificationNet, self).__init__()\n",
        "        self.embedding_net = embedding_net\n",
        "        self.n_classes = n_classes\n",
        "        self.latent_dim = latent_dim\n",
        "        self.nonlinear = nn.PReLU()\n",
        "        self.fc1 = nn.Linear(latent_dim, n_classes) # \n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.embedding_net(x)\n",
        "        output = self.nonlinear(output)\n",
        "        scores = F.log_softmax(self.fc1(output), dim=-1)\n",
        "        return scores\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        return self.nonlinear(self.embedding_net(x))\n",
        "\n",
        "embed_model = EmbeddingNet(latent_dim=512, architecture=152)\n",
        "x = torch.randn(1, 3, 64, 344)\n",
        "output = embed_model(x)\n",
        "print(output.shape)\n",
        "\n",
        "classifi = ClassificationNet(embed_model, 10, latent_dim=512)\n",
        "x = torch.randn(1, 3, 64, 344)\n",
        "output_class = classifi(x)\n",
        "print(output_class.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqmBBNVRcTrm",
        "outputId": "cf736b22-f999-4bbf-e565-9b5c8ff500c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 512])\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Feature Extractor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "class EfficentEmbeddingNet(nn.Module):\n",
        "    def __init__(self, latent_dim=128, architecture=0):\n",
        "        super(EfficentEmbeddingNet, self).__init__()\n",
        "        self.architecture = architecture\n",
        "        self.feature_extractor = self._getEfficientNet(latent_dim=latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "    def _getEfficientNet(self,latent_dim):\n",
        "        '''\n",
        "        Sprawdzic czy daje tez FC\n",
        "        '''\n",
        "        if self.architecture == 0:\n",
        "            model = models.efficientnet_b0(pretrained=True)\n",
        "        elif self.architecture == 1:\n",
        "            model = models.efficientnet_b1(pretrained=True)\n",
        "        elif self.architecture == 2:\n",
        "            model = models.efficientnet_b2(pretrained=True)\n",
        "        elif self.architecture == 3:\n",
        "            model = models.efficientnet_b3(pretrained=True)\n",
        "        elif self.architecture == 4:\n",
        "            model = models.efficientnet_b4(pretrained=True)\n",
        "        elif self.architecture == 5:\n",
        "            model = models.efficientnet_b5(pretrained=True)\n",
        "        elif self.architecture == 6:\n",
        "            model = models.efficientnet_b6(pretrained=True)\n",
        "        elif self.architecture == 7:\n",
        "            model = models.efficientnet_b7(pretrained=True)\n",
        "        else: print(\"MODEL NOT LOADED\")\n",
        "        \n",
        "        # to czy napewno tak\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad= False # freeze beggining layer\n",
        "        model.classifier[1] = nn.Linear(in_features=1280, out_features=latent_dim)\n",
        "        #print(model.classifier\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "class EfficentClassificationNet(nn.Module):\n",
        "    def __init__(self, embedding_net, n_classes, latent_dim):\n",
        "        super(EfficentClassificationNet, self).__init__()\n",
        "        self.embedding_net = embedding_net\n",
        "        self.n_classes = n_classes\n",
        "        self.latent_dim = latent_dim\n",
        "        self.nonlinear = nn.PReLU()\n",
        "        '''\n",
        "        Both Flatten and GlobalAveragePooling2D are valid options. So is GlobalMaxPooling2D.\n",
        "\n",
        "        Flatten will result in a larger Dense layer afterwards, which is \n",
        "        more expensive and may result in worse overfitting. But if you have lots of data, it might also perform better.\n",
        "\n",
        "        As usual, it depends completely on your problem.\n",
        "        '''\n",
        "        self.fc1 = nn.Linear(latent_dim, n_classes) # \n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.embedding_net(x)\n",
        "        output = self.nonlinear(output)\n",
        "        scores = F.log_softmax(self.fc1(output), dim=-1)\n",
        "        return scores\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        return self.nonlinear(self.embedding_net(x))\n",
        "\n",
        "embed_model = EfficentEmbeddingNet(latent_dim=512, architecture=0)\n",
        "x = torch.randn(1, 3, 64, 344)\n",
        "output = embed_model(x)\n",
        "print(output.shape)\n",
        "\n",
        "classifi = EfficentClassificationNet(embed_model, 10, latent_dim=512)\n",
        "x = torch.randn(1, 3, 64, 344)\n",
        "output_class = classifi(x)\n",
        "print(output_class.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIKK0buthejL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Feature Extractor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "class EfficentEmbeddingNet_other(nn.Module):\n",
        "    def __init__(self, latent_dim=128, architecture=0):\n",
        "        super(EfficentEmbeddingNet, self).__init__()\n",
        "        self.architecture = architecture\n",
        "        self.feature_extractor = self._getEfficientNet(latent_dim=latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)\n",
        "        return x\n",
        "\n",
        "    def _getEfficientNet(self,latent_dim):\n",
        "        '''\n",
        "        Sprawdzic czy daje tez FC\n",
        "        '''\n",
        "        if self.architecture == 0:\n",
        "            model = models.efficientnet_b0(pretrained=True)\n",
        "        elif self.architecture == 1:\n",
        "            model = models.efficientnet_b1(pretrained=True)\n",
        "        elif self.architecture == 2:\n",
        "            model = models.efficientnet_b2(pretrained=True)\n",
        "        elif self.architecture == 3:\n",
        "            model = models.efficientnet_b3(pretrained=True)\n",
        "        elif self.architecture == 4:\n",
        "            model = models.efficientnet_b4(pretrained=True)\n",
        "        elif self.architecture == 5:\n",
        "            model = models.efficientnet_b5(pretrained=True)\n",
        "        elif self.architecture == 6:\n",
        "            model = models.efficientnet_b6(pretrained=True)\n",
        "        elif self.architecture == 7:\n",
        "            model = models.efficientnet_b7(pretrained=True)\n",
        "        else: print(\"MODEL NOT LOADED\")\n",
        "        \n",
        "        # to czy napewno tak\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad= False # freeze beggining layer \n",
        "        \n",
        "        # przed 1280 na 10   >> global_average_pooling2d >> batch_normalization >>  (Dropout)  >> dense_6 (Dense) 1280 na 10\n",
        "        model.classifier[1] = nn.Linear(in_features=1280, out_features=10)\n",
        "        #print(model.classifier\n",
        "\n",
        "        return model\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        return self.forward(x)\n",
        "\n",
        "class EfficentClassificationNet(nn.Module):\n",
        "    def __init__(self, embedding_net, n_classes, latent_dim):\n",
        "        super(EfficentClassificationNet, self).__init__()\n",
        "        self.embedding_net = embedding_net\n",
        "        self.n_classes = n_classes\n",
        "        self.latent_dim = latent_dim\n",
        "        self.nonlinear = nn.PReLU()\n",
        "        '''\n",
        "        Both Flatten and GlobalAveragePooling2D are valid options. So is GlobalMaxPooling2D.\n",
        "\n",
        "        Flatten will result in a larger Dense layer afterwards, which is \n",
        "        more expensive and may result in worse overfitting. But if you have lots of data, it might also perform better.\n",
        "\n",
        "        As usual, it depends completely on your problem.\n",
        "        '''\n",
        "        self.fc1 = nn.Linear(latent_dim, n_classes) # \n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.embedding_net(x)\n",
        "        output = self.nonlinear(output)\n",
        "        scores = F.log_softmax(self.fc1(output), dim=-1)\n",
        "        return scores\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        return self.nonlinear(self.embedding_net(x))\n",
        "\n",
        "embed_model = EfficentEmbeddingNet(latent_dim=512, architecture=0)\n",
        "x = torch.randn(1, 3, 64, 344)\n",
        "output = embed_model(x)\n",
        "print(output.shape)\n",
        "\n",
        "classifi = EfficentClassificationNet(embed_model, 10, latent_dim=512)\n",
        "x = torch.randn(1, 3, 64, 344)\n",
        "output_class = classifi(x)\n",
        "print(output_class.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "model = models.efficientnet_b0(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad= False\n",
        "\n",
        "\n",
        "model\n",
        "#model.classifier[1] = nn.Linear(in_features=1280, out_features=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgne3kKoERFY",
        "outputId": "dc8d997b-3a00-4127-9ffd-08ae7c471075"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (features): Sequential(\n",
              "    (0): ConvNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (2): ConvNormActivation(\n",
              "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "      )\n",
              "      (3): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): ConvNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): ConvNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): ConvNormActivation(\n",
              "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (8): ConvNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=True)\n",
              "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier[1] = nn.Linear(in_featyures, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiDMAf0IE9__",
        "outputId": "b4c53f2d-d40c-42b1-dfa6-3676781a161f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaptiveAvgPool2d(output_size=1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RHII0AR9e5V"
      },
      "outputs": [],
      "source": [
        "# idal train loop\n",
        "'''\n",
        "2. early stopping\n",
        "3. easy connect to weights and biases\n",
        "4. latwa w modulowaniu\n",
        "5. loss/accuracy i inne jesli potrzebne\n",
        "6. tqdm albo w&b\n",
        "7. print co iles mini batch np 10% epoki\n",
        "'''\n",
        "def train_epoch(train_loader, optimizer, device, model, loss_fn, log_interval):\n",
        "    running_loss = 0.\n",
        "    train_loss = 0.\n",
        "    for i, data in enumerate(train_loader):\n",
        "        images, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        preds = model(images)\n",
        "        loss = loss_fn(preds, labels)\n",
        "        loss.backward() # Calculates the backward gradients over the learning weights\n",
        "\n",
        "        optimizer.step() # Tells the optimizer to perform one learning step - that is, adjust the model’s learning weights\n",
        "                         # based on the observed gradients for this batch, according to the optimization algorithm we chose It\n",
        "                         #  reports on the loss for every log_interval. (log_interval = 500) -> every 500 batches\n",
        "        running_loss += loss.item()\n",
        "        if i % log_interval == 0:\n",
        "            train_loss = running_loss / loss # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, train_loss))\n",
        "            running_loss = 0.\n",
        "    return train_loss # loss calej epoki\n",
        "\n",
        "def test_epoch(test_loader, model, device, loss_fn, save_best=False):\n",
        "    '''\n",
        "    OUTPUT\n",
        "    jesli chce sie dokladnosc w procentach to pomnozyc correct * 100 !\n",
        "    '''\n",
        "    best_accuracy = 0\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    size = len(test_loader.dataset) # ? czy to naprwno tak sprawdzic\n",
        "    num_batches = len(test_loader)  # ?\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            preds = model(images)\n",
        "            test_loss += loss_fn(preds, labels).item()\n",
        "            correct += (preds.argmax(1) == labels).type(torch.float).sum().item()\n",
        "    test_loss = test_loss / num_batches\n",
        "    correct = correct / size\n",
        "    if save_best is True:\n",
        "        if correct > best_accuracy:\n",
        "            torch.save(model, 'best-model.pt')\n",
        "            torch.save(model.state_dict(), 'best-model-parameters.pt')\n",
        "            best_accuracy = correct\n",
        "    print(\"Accuracy {}, Test_loss {}\".format(correct*100, test_loss))\n",
        "    return correct, test_loss\n",
        "\n",
        "def train_model(epoch, model, train_loader, test_loader, optimizer, device, loss_fn, scheduler, log_interval, save_best=False, start_epoch=0):\n",
        "    for i in range(0, start_epoch): # po co ? bo dziala od ktorejs epoki czasami !!!\n",
        "        scheduler.step()\n",
        "\n",
        "    train_loss_tab = []\n",
        "    test_loss_tab = []\n",
        "    accuracy_tab = []\n",
        "    for i in range(start_epoch, epoch):\n",
        "        train_loss = train_epoch(train_loader, optimizer, device, model, loss_fn, log_interval)\n",
        "        accuracy, test_loss = test_epoch(test_loader, model, device, loss_fn, save_best=False)\n",
        "        scheduler.step()\n",
        "        train_loss_tab.append(train_loss)\n",
        "        test_loss_tab.append(test_loss)\n",
        "        accuracy_tab.append(accuracy)\n",
        "    return train_loss_tab, test_loss_tab, accuracy_tab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6wTiYOtbYkm",
        "outputId": "b2a21161-2d1c-4350-e3e8-a3a8db37a99a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch.optim.lr_scheduler\n",
        "import torch.optim\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "latent_dim = 128\n",
        "\n",
        "embedding_model = EmbeddingNet(latent_dim=latent_dim, architecture=34).to(device)\n",
        "model_classification = ClassificationNet(embedding_model, 10, latent_dim=latent_dim).to(device)\n",
        "\n",
        "loss_fn = torch.nn.NLLLoss()\n",
        "lr = 1e-2\n",
        "optimizer = torch.optim.Adam(model_classification.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)\n",
        "n_epochs = 5\n",
        "log_interval = 50 # ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFBENSfm7xr0",
        "outputId": "ffb6eb6e-f593-42ae-ce31-16a2df258c3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 100.00543975830078\n",
            "  batch 201 loss: 102.75122833251953\n",
            "  batch 301 loss: 105.60599517822266\n",
            "Accuracy 36.0919540229885, Test_loss 1.7908680148240996\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 92.45731353759766\n",
            "  batch 201 loss: 96.13599395751953\n",
            "  batch 301 loss: 121.52803039550781\n",
            "Accuracy 33.639846743295024, Test_loss 1.8284321732637359\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 96.44847869873047\n",
            "  batch 201 loss: 111.07157135009766\n",
            "  batch 301 loss: 85.91714477539062\n",
            "Accuracy 37.01149425287356, Test_loss 1.8034587139036597\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 108.36941528320312\n",
            "  batch 201 loss: 123.77244567871094\n",
            "  batch 301 loss: 81.65238189697266\n",
            "Accuracy 38.31417624521073, Test_loss 1.6580796619740927\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 93.16629028320312\n",
            "  batch 201 loss: 111.26626586914062\n",
            "  batch 301 loss: 114.9343032836914\n",
            "Accuracy 40.689655172413794, Test_loss 1.671766534084227\n"
          ]
        }
      ],
      "source": [
        "train_tab, test_tab, acc_tab = train_model(epoch=n_epochs,\n",
        "                                           model=model_classification,\n",
        "                                           train_loader=train_dl,\n",
        "                                           test_loader=test_dl,\n",
        "                                           optimizer=optimizer,\n",
        "                                           device=device,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           scheduler=scheduler,\n",
        "                                           log_interval=100, # to lepiej ogarnac\n",
        "                                           save_best=True,\n",
        "                                           start_epoch=0)\n",
        "# 25min 1 epoka na resnet  50  - 30 sek dane\n",
        "# 24:47 start 15min  epoka jakos\n",
        "# preprocess danych nie jest nma gpu chyba dlatego tak dlugo to trwa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOyvG4mNOIqr"
      },
      "outputs": [],
      "source": [
        "# rozpisac ktore zle/dobrze klasyfikuje z kazdego gatunku i dlaczwego \n",
        "# ten wykres jebany se zrobic\n",
        "# Dataset usprawnic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5zza4Jg0Ww9"
      },
      "outputs": [],
      "source": [
        "def extract_embeddings(dataloader, model):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        embeddings = np.zeros((len(dataloader.dataset), 2))\n",
        "        labels = np.zeros(len(dataloader.dataset))\n",
        "        k = 0\n",
        "        for images, target in dataloader:\n",
        "            if cuda:\n",
        "                images = images.cuda()\n",
        "            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()\n",
        "            labels[k:k+len(images)] = target.numpy()\n",
        "            k += len(images)\n",
        "    return embeddings, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8TsRMG3OIKp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCJt0ZRd0wN6"
      },
      "outputs": [],
      "source": [
        "#Reduce with PCA or Tsne 128 dim to only 2\n",
        "# pca wszytsjkie naraz\n",
        "# w ktorych mozna dorzucac jak w embedding; na apke"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CNusIxw0rZe"
      },
      "outputs": [],
      "source": [
        "def plot_embeddings(embeddings, targets, xlim=None, ylim=None):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i in range(10):\n",
        "        inds = np.where(targets==i)[0]\n",
        "        plt.scatter(embeddings[inds,0], embeddings[inds,1], alpha=0.5, color=colors[i])\n",
        "    if xlim:\n",
        "        plt.xlim(xlim[0], xlim[1])\n",
        "    if ylim:\n",
        "        plt.ylim(ylim[0], ylim[1])\n",
        "    plt.legend(mnist_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb9cugU0pTHS"
      },
      "outputs": [],
      "source": [
        "# Plot embeddings in Weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjoz92tpeEdz",
        "outputId": "b18f5f57-bcd3-493b-9d3c-d391ec04d4a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.6.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.6.3\n"
          ]
        }
      ],
      "source": [
        "pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iESg4tDIqxGV",
        "outputId": "86a7828b-8e86-4883-86ca-63ad147f1b8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                             Output Shape              Param #\n",
              "====================================================================================================\n",
              "ClassificationNet                                  --                        --\n",
              "├─EmbeddingNet: 1-1                                [1, 512]                  --\n",
              "│    └─ResNet: 2-1                                 [1, 512]                  --\n",
              "│    │    └─Conv2d: 3-1                            [1, 64, 32, 1290]         (9,408)\n",
              "│    │    └─BatchNorm2d: 3-2                       [1, 64, 32, 1290]         (128)\n",
              "│    │    └─ReLU: 3-3                              [1, 64, 32, 1290]         --\n",
              "│    │    └─MaxPool2d: 3-4                         [1, 64, 16, 645]          --\n",
              "│    │    └─Sequential: 3-5                        [1, 256, 16, 645]         (215,808)\n",
              "│    │    └─Sequential: 3-6                        [1, 512, 8, 323]          (2,339,840)\n",
              "│    │    └─Sequential: 3-7                        [1, 1024, 4, 162]         (40,613,888)\n",
              "│    │    └─Sequential: 3-8                        [1, 2048, 2, 81]          (14,964,736)\n",
              "│    │    └─AdaptiveAvgPool2d: 3-9                 [1, 2048, 1, 1]           --\n",
              "│    │    └─Linear: 3-10                           [1, 512]                  1,049,088\n",
              "├─PReLU: 1-2                                       [1, 512]                  1\n",
              "├─Linear: 1-3                                      [1, 10]                   5,130\n",
              "====================================================================================================\n",
              "Total params: 59,198,027\n",
              "Trainable params: 1,054,219\n",
              "Non-trainable params: 58,143,808\n",
              "Total mult-adds (G): 38.03\n",
              "====================================================================================================\n",
              "Input size (MB): 1.98\n",
              "Forward/backward pass size (MB): 1190.83\n",
              "Params size (MB): 236.79\n",
              "Estimated Total Size (MB): 1429.60\n",
              "===================================================================================================="
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "summary(model_classification, input_size=(1, 3, 64, 2579))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5YdqH-bN--R"
      },
      "source": [
        "# TODO\n",
        "\n",
        "1. preprocess szybszy (zmiana na zdjecia gotowe juz)\n",
        "2. W&B\n",
        "3. model z gtzan < -- (do tego w&b ny sie przydalo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa-sgY8y5v4q"
      },
      "source": [
        "# W&B Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJygTLkyp23R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import random_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFAdJhTB5yJj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wandb --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpOS2Tugp4iu"
      },
      "outputs": [],
      "source": [
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "lmyFDb5O51C1",
        "outputId": "83c30ae2-8b2b-473c-89c2-caf67be1cc47"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePE57Yub525Q"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    'method' : 'random',\n",
        "}\n",
        "metric = {\n",
        "    'name' : 'test_loss',\n",
        "    'goal' : 'minimize'\n",
        "}\n",
        "sweep_config['metric'] = metric\n",
        "# name the hperparameters\n",
        "parameters_dict = {\n",
        "    'epochs': {\n",
        "        'values': [3, 5]\n",
        "    },\n",
        "    'batch_size': {\n",
        "        'values': [16, 32, 64]\n",
        "    },\n",
        "    'duration': {\n",
        "        'values': [4000, 8000, 15000, 25000] # /1000 zeby bylo w sekundach\n",
        "    },\n",
        "    'shift_pct': {\n",
        "        'values': [0.4, 0.2]\n",
        "    },\n",
        "    'latent_dim': {\n",
        "        'values': [256, 512]\n",
        "    },\n",
        "    'optimizer': {\n",
        "        'values': ['adam', 'sgd', 'RMSprop'] # z scheduler\n",
        "    },\n",
        "    'scheduler': {\n",
        "        'values': ['ExponentialLR', 'CyclicLR - exp_range'] # z scheduler\n",
        "    },\n",
        "    'models': {\n",
        "        'values': ['Resnet34', 'EfficentNet0'] # z scheduler\n",
        "    }\n",
        "}\n",
        "sweep_config['parameters'] = parameters_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAvq2pTyESNZ",
        "outputId": "48140b04-77c4-42af-d900-50924a7617e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'method': 'random',\n",
            " 'metric': {'goal': 'minimize', 'name': 'test_loss'},\n",
            " 'parameters': {'batch_size': {'values': [16, 32, 64]},\n",
            "                'duration': {'values': [4000, 8000, 15000, 25000]},\n",
            "                'epochs': {'values': [3, 5]},\n",
            "                'latent_dim': {'values': [256, 512]},\n",
            "                'models': {'values': ['Resnet34', 'EfficentNet0']},\n",
            "                'optimizer': {'values': ['adam', 'sgd', 'RMSprop']},\n",
            "                'scheduler': {'values': ['ExponentialLR',\n",
            "                                         'CyclicLR - exp_range']},\n",
            "                'shift_pct': {'values': [0.4, 0.2]}}}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(sweep_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97T5pFfVEMwg",
        "outputId": "ba07c183-6a6b-481f-da71-382956af510d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: xpt0sfaz\n",
            "Sweep URL: https://wandb.ai/wualas/MUSIC_CLASSIFICATION/sweeps/xpt0sfaz\n"
          ]
        }
      ],
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"MUSIC_CLASSIFICATION\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrcKhcoUFt5D"
      },
      "outputs": [],
      "source": [
        "def build_network(model_name, latent_dim):\n",
        "    # do zmiany ale izi\n",
        "    if model_name == 'Resnet18':\n",
        "        architecture = 18\n",
        "        embed_model = EmbeddingNet(latent_dim=latent_dim, architecture=architecture).to(device)\n",
        "        model = ClassificationNet(embed_model, 10, latent_dim=latent_dim).to(device)\n",
        "    if model_name == 'Resnet34':\n",
        "        architecture = 34\n",
        "        embed_model = EmbeddingNet(latent_dim=latent_dim, architecture=architecture).to(device)\n",
        "        model = ClassificationNet(embed_model, 10, latent_dim=latent_dim).to(device)\n",
        "    if model_name == 'EfficentNet0':\n",
        "        architecture = 0\n",
        "        embed_model = EfficentEmbeddingNet(latent_dim=latent_dim, architecture=architecture).to(device)\n",
        "        model = EfficentClassificationNet(embed_model, 10, latent_dim=latent_dim).to(device)\n",
        "    if model_name == 'MyFuckingNetwork':\n",
        "        model = MyFuckingNetwork().to(device)\n",
        "    return model\n",
        "\n",
        "def build_optimizer(network, optimizer):\n",
        "    if optimizer == \"sgd\":\n",
        "        optimizer = torch.optim.SGD(network.parameters(),\n",
        "                              lr=0.01, momentum=0.9)\n",
        "    elif optimizer == \"adam\":\n",
        "        optimizer = torch.optim.Adam(network.parameters(),\n",
        "                               lr=3e-4)\n",
        "    elif optimizer == 'RMSprop':\n",
        "        optimizer = torch.optim.RMSprop(network.parameters(),\n",
        "                                lr=0.01)\n",
        "    return optimizer\n",
        "\n",
        "def build_scheduler(optimizer, scheduler):\n",
        "    '''\n",
        "    w schedulerach jest tyle hiperparametrow ze japierodle\n",
        "    '''\n",
        "    if scheduler == 'ExponentialLR':\n",
        "      scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
        "          optimizer, gamma=0.1\n",
        "      )\n",
        "    elif scheduler == 'CyclicLR - exp_range':\n",
        "      scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
        "          optimizer, base_lr=0.001, max_lr=0.1,step_size_up=5,\n",
        "          mode=\"exp_range\",gamma=0.85, cycle_momentum=False\n",
        "      )\n",
        "    return scheduler\n",
        "\n",
        "def build_loader(df, data_path, batch_size, duration=30000, shift_pct=0.4, experimental=None):\n",
        "    '''\n",
        "    experimental = 0.6 menas that 60% of dataset will be deleted for wandb research\n",
        "    '''\n",
        "    myds = SoundDS(df, data_path, duration=duration, shift_pct=shift_pct)\n",
        "\n",
        "    # Random split of 80:20 between training and validation\n",
        "    num_items = len(myds)\n",
        "\n",
        "\n",
        "    if experimental != None:\n",
        "        to_remove = round(num_items * experimental)\n",
        "        num_items = len(myds) - to_remove\n",
        "        num_train = round(num_items * 0.8)\n",
        "        num_val = num_items - num_train\n",
        "        remove_ds, train_ds, test_ds = random_split(myds, [to_remove,num_train, num_val])\n",
        "        print(\"WORKS\")\n",
        "    else:\n",
        "        num_train = round(num_items * 0.8)\n",
        "        num_val = num_items - num_train\n",
        "        train_ds, test_ds = random_split(myds, [num_train, num_val])\n",
        "    # Create training and validation data loaders\n",
        "    # batch_size jak dobierac spradzic\n",
        "    train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_dl, test_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JSW1dgvEZwd"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "df = pd.read_csv(\"/content/CNN_CLASIFIER_annotations_withgtzan_v2.csv\")\n",
        "data_path = \"/content/dataset/\"\n",
        "\n",
        "def train_model_wandb(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "        train_dl, test_dl = build_loader(df, data_path, config.batch_size, config.duration, config.shift_pct, experimental=0.6)\n",
        "        model = build_network(config.models, config.latent_dim)\n",
        "        optimizer = build_optimizer(model, config.optimizer)\n",
        "        scheduler = build_scheduler(optimizer, config.scheduler)\n",
        "        for epoch in range(config.epochs):\n",
        "            print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
        "            train_loss = train_epoch(train_dl, optimizer, device, model, loss_fn, 100)\n",
        "            accuracy, test_loss = test_epoch(test_dl, model, device, loss_fn, save_best=False)\n",
        "            scheduler.step()\n",
        "            wandb.log({'epoch': epoch, 'test_loss': test_loss, 'train_loss': train_loss, 'accuracy': accuracy})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b6f3db939ead42359662df4bc928df81",
            "8f93ab73ceca4f3383e94c644007889e",
            "cbe99a6aaa654aa4bc42f95853d65984",
            "139af91bd5d745568727c338214451e6",
            "3b9b2a24828f4534a29d9fd8f0ab33c8",
            "e2eef2e2ec0a445f9b85c4ea41e5e338",
            "e94bdf8725cd4a21826e9da8284409e0",
            "43534dfd7db646cea4c943e54ebf8c85",
            "68f57097958a4f558abacc5eaae26812",
            "9cf9dab5f610456c8372980004954830",
            "4d6834a05bae4d8abc79a6b9bd3785aa",
            "b3aeaa347d3d406fa6015fa1154f783e",
            "85903978e15c4a09852aaa961c8df02f",
            "7bf23a159729400db864e46917c94a02",
            "cb9d2d2c7e7f414691380046fa335e3c",
            "3bf772c8fca64575acb54e86827986ee",
            "a522d4dd7f8047d39c69303ca3e32337",
            "04d909d047854f8bbe7eeacbaffc0876",
            "0747c41f12ab49b7a7dc6dfd4ce60967",
            "5b35a10dc32c46b99426d48c3be58852",
            "003d53ac4b69472ba2e6f6c0a682184d",
            "89154618937d4477a736fa93267ad9d8",
            "27f92016d6874244907d93d3f4890d18",
            "cf8a2238352c4014a21ae57438573942"
          ]
        },
        "id": "7BVDPRUeEQlz",
        "outputId": "134e5831-1bb0-459d-d9f2-9b8bcf9fc0e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xm369377 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tduration: 8000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: EfficentNet0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: ExponentialLR\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tshift_pct: 0.2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220401_162408-xm369377</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/runs/xm369377\" target=\"_blank\">desert-sweep-6</a></strong> to <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/sweeps/xpt0sfaz\" target=\"_blank\">https://wandb.ai/wualas/MUSIC_CLASSIFICATION/sweeps/xpt0sfaz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WORKS\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 113.75459289550781\n",
            "  batch 201 loss: 104.04815673828125\n",
            "Accuracy 39.272030651341, Test_loss 1.6987473495078809\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 118.47662353515625\n",
            "  batch 201 loss: 76.14639282226562\n",
            "Accuracy 47.509578544061306, Test_loss 1.544988650264162\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 121.53935241699219\n",
            "  batch 201 loss: 130.8271484375\n",
            "Accuracy 46.36015325670498, Test_loss 1.5702572853276224\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "  batch 1 loss: 0.9999999403953552\n",
            "  batch 101 loss: 96.98963165283203\n",
            "  batch 201 loss: 127.63470458984375\n",
            "Accuracy 44.827586206896555, Test_loss 1.5866799769979534\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6f3db939ead42359662df4bc928df81",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁█▇▆</td></tr><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>test_loss</td><td>█▁▂▃</td></tr><tr><td>train_loss</td><td>▅▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.44828</td></tr><tr><td>epoch</td><td>3</td></tr><tr><td>test_loss</td><td>1.58668</td></tr><tr><td>train_loss</td><td>127.6347</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">desert-sweep-6</strong>: <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/runs/xm369377\" target=\"_blank\">https://wandb.ai/wualas/MUSIC_CLASSIFICATION/runs/xm369377</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220401_162408-xm369377/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cpn47oy6 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tduration: 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: Resnet34\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: RMSprop\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: CyclicLR - exp_range\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tshift_pct: 0.4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220401_164847-cpn47oy6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/runs/cpn47oy6\" target=\"_blank\">rich-sweep-7</a></strong> to <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/sweeps/xpt0sfaz\" target=\"_blank\">https://wandb.ai/wualas/MUSIC_CLASSIFICATION/sweeps/xpt0sfaz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WORKS\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 141.89784240722656\n",
            "Accuracy 32.18390804597701, Test_loss 1.8987957239151\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 3644.871337890625\n",
            "Accuracy 19.157088122605366, Test_loss 2.2052187197136157\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 3664.314697265625\n",
            "Accuracy 21.455938697318008, Test_loss 2.222345297986811\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 12126.6025390625\n",
            "Accuracy 28.35249042145594, Test_loss 2.1966320420756484\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 2.0980050563812256\n",
            "Accuracy 20.689655172413794, Test_loss 22.389896884109035\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "  batch 101 loss: 163.32737731933594\n",
            "Accuracy 6.321839080459771, Test_loss 23.241143255522758\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68f57097958a4f558abacc5eaae26812",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>█▄▅▇▅▁</td></tr><tr><td>epoch</td><td>▁▂▄▅▇█</td></tr><tr><td>test_loss</td><td>▁▁▁▁██</td></tr><tr><td>train_loss</td><td>▁▃▃█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.06322</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>test_loss</td><td>23.24114</td></tr><tr><td>train_loss</td><td>163.32738</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">rich-sweep-7</strong>: <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/runs/cpn47oy6\" target=\"_blank\">https://wandb.ai/wualas/MUSIC_CLASSIFICATION/runs/cpn47oy6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220401_164847-cpn47oy6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qwgvj81i with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tduration: 4000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: Resnet18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: CyclicLR - exp_range\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tshift_pct: 0.6\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220401_172204-qwgvj81i</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/runs/qwgvj81i\" target=\"_blank\">fine-sweep-8</a></strong> to <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/sweeps/xpt0sfaz\" target=\"_blank\">https://wandb.ai/wualas/MUSIC_CLASSIFICATION/sweeps/xpt0sfaz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WORKS\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "Accuracy 36.59003831417624, Test_loss 1.8100581519743975\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "Accuracy 31.03448275862069, Test_loss 2.0656288511612835\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a522d4dd7f8047d39c69303ca3e32337",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>█▁</td></tr><tr><td>epoch</td><td>▁█</td></tr><tr><td>test_loss</td><td>▁█</td></tr><tr><td>train_loss</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.31034</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>test_loss</td><td>2.06563</td></tr><tr><td>train_loss</td><td>1.0</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">fine-sweep-8</strong>: <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/runs/qwgvj81i\" target=\"_blank\">https://wandb.ai/wualas/MUSIC_CLASSIFICATION/runs/qwgvj81i</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220401_172204-qwgvj81i/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vcxjrsc4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tduration: 25000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodels: Resnet18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler: CyclicLR - exp_range\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tshift_pct: 0.2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220401_173246-vcxjrsc4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/runs/vcxjrsc4\" target=\"_blank\">woven-sweep-9</a></strong> to <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/wualas/MUSIC_CLASSIFICATION/sweeps/xpt0sfaz\" target=\"_blank\">https://wandb.ai/wualas/MUSIC_CLASSIFICATION/sweeps/xpt0sfaz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WORKS\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n",
            "Accuracy 24.71264367816092, Test_loss 2.1506599850124783\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "  batch 1 loss: 1.0\n"
          ]
        }
      ],
      "source": [
        "wandb.agent(sweep_id, function=train_model_wandb, count=5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Music System Recommender.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "003d53ac4b69472ba2e6f6c0a682184d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d909d047854f8bbe7eeacbaffc0876": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_003d53ac4b69472ba2e6f6c0a682184d",
            "placeholder": "​",
            "style": "IPY_MODEL_89154618937d4477a736fa93267ad9d8",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "0747c41f12ab49b7a7dc6dfd4ce60967": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27f92016d6874244907d93d3f4890d18",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf8a2238352c4014a21ae57438573942",
            "value": 1
          }
        },
        "0d37f049421647aabe68780c4ba21baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "139af91bd5d745568727c338214451e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "223f473b59b0449a90e012bec28f56d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27f92016d6874244907d93d3f4890d18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b9b2a24828f4534a29d9fd8f0ab33c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bf772c8fca64575acb54e86827986ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "427bd2d58ae045a78cad739d61ec5cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43534dfd7db646cea4c943e54ebf8c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d6834a05bae4d8abc79a6b9bd3785aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb9d2d2c7e7f414691380046fa335e3c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bf772c8fca64575acb54e86827986ee",
            "value": 1
          }
        },
        "56e2c1e656d444bca67da2dfb057a3b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b35a10dc32c46b99426d48c3be58852": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f57097958a4f558abacc5eaae26812": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cf9dab5f610456c8372980004954830",
              "IPY_MODEL_4d6834a05bae4d8abc79a6b9bd3785aa"
            ],
            "layout": "IPY_MODEL_b3aeaa347d3d406fa6015fa1154f783e"
          }
        },
        "69a73f4d56314142966c45bb276610e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_223f473b59b0449a90e012bec28f56d4",
            "placeholder": "​",
            "style": "IPY_MODEL_cc14244e8b4e4196ae07684d59f97771",
            "value": " 230M/230M [00:04&lt;00:00, 65.5MB/s]"
          }
        },
        "7bf23a159729400db864e46917c94a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "810190a8d2ab4191a09425043dcfa6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b60449d2bd4a40b66865b1fbae09fb",
            "placeholder": "​",
            "style": "IPY_MODEL_427bd2d58ae045a78cad739d61ec5cec",
            "value": "100%"
          }
        },
        "85903978e15c4a09852aaa961c8df02f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89154618937d4477a736fa93267ad9d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f93ab73ceca4f3383e94c644007889e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b9b2a24828f4534a29d9fd8f0ab33c8",
            "placeholder": "​",
            "style": "IPY_MODEL_e2eef2e2ec0a445f9b85c4ea41e5e338",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "9cf9dab5f610456c8372980004954830": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85903978e15c4a09852aaa961c8df02f",
            "placeholder": "​",
            "style": "IPY_MODEL_7bf23a159729400db864e46917c94a02",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "9fd16236b9bb4aa4bb5c9ba253ba36da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a522d4dd7f8047d39c69303ca3e32337": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04d909d047854f8bbe7eeacbaffc0876",
              "IPY_MODEL_0747c41f12ab49b7a7dc6dfd4ce60967"
            ],
            "layout": "IPY_MODEL_5b35a10dc32c46b99426d48c3be58852"
          }
        },
        "b3aeaa347d3d406fa6015fa1154f783e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6f3db939ead42359662df4bc928df81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f93ab73ceca4f3383e94c644007889e",
              "IPY_MODEL_cbe99a6aaa654aa4bc42f95853d65984"
            ],
            "layout": "IPY_MODEL_139af91bd5d745568727c338214451e6"
          }
        },
        "c0b60449d2bd4a40b66865b1fbae09fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb1bd6b776034bf0a3ed8f7360e1f786": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_810190a8d2ab4191a09425043dcfa6ec",
              "IPY_MODEL_d5d13f06c0224691a814d3ed5c43a49d",
              "IPY_MODEL_69a73f4d56314142966c45bb276610e9"
            ],
            "layout": "IPY_MODEL_9fd16236b9bb4aa4bb5c9ba253ba36da"
          }
        },
        "cb9d2d2c7e7f414691380046fa335e3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe99a6aaa654aa4bc42f95853d65984": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e94bdf8725cd4a21826e9da8284409e0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43534dfd7db646cea4c943e54ebf8c85",
            "value": 1
          }
        },
        "cc14244e8b4e4196ae07684d59f97771": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf8a2238352c4014a21ae57438573942": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5d13f06c0224691a814d3ed5c43a49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56e2c1e656d444bca67da2dfb057a3b1",
            "max": 241627721,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d37f049421647aabe68780c4ba21baf",
            "value": 241627721
          }
        },
        "e2eef2e2ec0a445f9b85c4ea41e5e338": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e94bdf8725cd4a21826e9da8284409e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}